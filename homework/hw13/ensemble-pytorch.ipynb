{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Bai04_BTVN ensemble_pytorch.ipynb","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"280fb25dba9a4c71919f14860d9dca9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c25571d57d046cba2c58397ddc34b19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_735369df2ed64befbf8881dfcce5ac59","IPY_MODEL_b87b07022dbf4813b8167d41eff89636","IPY_MODEL_901e1198a6dd47b1a22a5d1b3f118223"],"layout":"IPY_MODEL_ca25ccb0f27245c6843719f8c9230d72"}},"2c3c1dd048e249f1b509608f4f6742b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"315d54783e0b4990ac968204723cc721":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"321a89271cd4410286411128362354e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47520650afa140fa9b790b18d93a47f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"735369df2ed64befbf8881dfcce5ac59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_280fb25dba9a4c71919f14860d9dca9e","placeholder":"​","style":"IPY_MODEL_2c3c1dd048e249f1b509608f4f6742b6","value":""}},"901e1198a6dd47b1a22a5d1b3f118223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_315d54783e0b4990ac968204723cc721","placeholder":"​","style":"IPY_MODEL_47520650afa140fa9b790b18d93a47f1","value":" 170499072/? [00:03&lt;00:00, 48528568.92it/s]"}},"b8001ce77991495c9b07566c3d033921":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b87b07022dbf4813b8167d41eff89636":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8001ce77991495c9b07566c3d033921","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_321a89271cd4410286411128362354e0","value":170498071}},"ca25ccb0f27245c6843719f8c9230d72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BTVN: Training Neural Networks (Tiếp)\nTrong phần này các bạn sẽ làm quen với kỹ thuật model ensemble để tăng độ chính xác khi suy diễn","metadata":{"id":"CspDnsdcmRze"}},{"cell_type":"code","source":"!nvidia-smi\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport glob\nimport cv2\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dALhhAr_5agu","outputId":"24bf54a0-ecfc-414b-812f-5b865ce3ce50","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:22.647982Z","iopub.execute_input":"2025-10-25T13:33:22.648381Z","iopub.status.idle":"2025-10-25T13:33:22.830907Z","shell.execute_reply.started":"2025-10-25T13:33:22.648350Z","shell.execute_reply":"2025-10-25T13:33:22.830148Z"}},"outputs":[{"name":"stdout","text":"Sat Oct 25 13:33:22 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             32W /  250W |     321MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Tải dữ liệu","metadata":{}},{"cell_type":"code","source":"def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=True, download=True, transform=transform)\n\n    testset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset\n\ntrainset, testset = load_data('./data')\ntrainloader = torch.utils.data.DataLoader(\n    trainset,\n    batch_size=128,\n    shuffle=True,\n)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=4, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:22.832579Z","iopub.execute_input":"2025-10-25T13:33:22.832859Z","iopub.status.idle":"2025-10-25T13:33:24.461028Z","shell.execute_reply.started":"2025-10-25T13:33:22.832836Z","shell.execute_reply":"2025-10-25T13:33:24.460475Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Tải dữ liệu và cài đặt một kiến trúc mạng nơ-ron đơn giản theo mô tả phía dưới","metadata":{"id":"1_jDYArKvZ-Z"}},{"cell_type":"code","source":"class Net(nn.Module):\n    ######################\n    ### YOUR CODE HERE ###\n    def __init__(self, l1=120, l2=84):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.linear1 = nn.Linear(16*5*5, l1)\n        self.linear2 = nn.Linear(l1, l2)\n        self.linear3 = nn.Linear(l2, 10)\n    ######################\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16*5*5)\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x\n\nmodel = Net()\nif torch.cuda.is_available():\n    model.cuda()\nsummary(model, (3, 32, 32))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptNpnOaYCuK6","outputId":"a42080d5-2678-4726-f951-c71590c8c034","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:24.461636Z","iopub.execute_input":"2025-10-25T13:33:24.461823Z","iopub.status.idle":"2025-10-25T13:33:24.475138Z","shell.execute_reply.started":"2025-10-25T13:33:24.461808Z","shell.execute_reply":"2025-10-25T13:33:24.474578Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 6, 28, 28]             456\n         MaxPool2d-2            [-1, 6, 14, 14]               0\n            Conv2d-3           [-1, 16, 10, 10]           2,416\n         MaxPool2d-4             [-1, 16, 5, 5]               0\n            Linear-5                  [-1, 120]          48,120\n            Linear-6                   [-1, 84]          10,164\n            Linear-7                   [-1, 10]             850\n================================================================\nTotal params: 62,006\nTrainable params: 62,006\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.06\nParams size (MB): 0.24\nEstimated Total Size (MB): 0.31\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Hàm đánh giá độ chính xác trên tập test","metadata":{}},{"cell_type":"code","source":"def test_accuracy(net, device=\"cpu\"):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            ######################\n            ### YOUR CODE HERE ###\n            outputs = net(images)\n            _, y_preds = torch.max(outputs.data, 1)\n            \n            correct += torch.sum(torch.eq(y_preds, labels)).item()\n            total += labels.size(0)\n            ######################\n    return correct / total","metadata":{"id":"GV63_UK5SqbP","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:24.475902Z","iopub.execute_input":"2025-10-25T13:33:24.476184Z","iopub.status.idle":"2025-10-25T13:33:24.487778Z","shell.execute_reply.started":"2025-10-25T13:33:24.476167Z","shell.execute_reply":"2025-10-25T13:33:24.487191Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Hàm huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"def train(net, criterion, optimizer, save_path, device=\"cpu\", epochs = 10,warm_epoch = 5, init_lr = 1e-2,last_lr = 1e-4, T_max = 10):\n    T_cur = 0\n    for epoch in range(1, epochs+1):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        T_cur += 1\n        \n        # warm-up\n        if epoch <= warm_epoch:\n            optimizer.param_groups[0]['lr'] = (1.0 * epoch) / warm_epoch  * init_lr\n        else: \n            # cosine annealing lr\n            optimizer.param_groups[0]['lr'] = last_lr + (init_lr - last_lr) * (1 + np.cos(T_cur * np.pi / T_max)) / 2\n\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i + 1 == len(trainloader):\n                print(\"[Epoch %d] loss: %.3f\" % (epoch, running_loss / epoch_steps))\n                running_loss = 0.0\n                \n    print(\"Finished Training\")\n    print(\"Test accuracy:\", test_accuracy(net, device))\n    torch.save(net.state_dict(), save_path)","metadata":{"id":"Bk1YvtHgOKqk","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:24.489070Z","iopub.execute_input":"2025-10-25T13:33:24.489261Z","iopub.status.idle":"2025-10-25T13:33:24.504823Z","shell.execute_reply.started":"2025-10-25T13:33:24.489246Z","shell.execute_reply":"2025-10-25T13:33:24.504099Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Thiết lập các tham số và hai kiến trúc mạng khác nhau","metadata":{}},{"cell_type":"code","source":"epochs = 10\nwarm_epoch = 5\ninit_lr = 1e-2\nlast_lr = 1e-4\nT_max = epochs\n\nconfigs = [{'l1': 64, 'l2': 32}, {'l1': 128, 'l2': 64}]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["2c25571d57d046cba2c58397ddc34b19","ca25ccb0f27245c6843719f8c9230d72","735369df2ed64befbf8881dfcce5ac59","b87b07022dbf4813b8167d41eff89636","901e1198a6dd47b1a22a5d1b3f118223","2c3c1dd048e249f1b509608f4f6742b6","280fb25dba9a4c71919f14860d9dca9e","321a89271cd4410286411128362354e0","b8001ce77991495c9b07566c3d033921","47520650afa140fa9b790b18d93a47f1","315d54783e0b4990ac968204723cc721"]},"id":"mS4soUx9iwvh","outputId":"c054257d-2fdd-4379-8e42-bca90aa16904","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:24.505449Z","iopub.execute_input":"2025-10-25T13:33:24.505623Z","iopub.status.idle":"2025-10-25T13:33:24.521355Z","shell.execute_reply.started":"2025-10-25T13:33:24.505609Z","shell.execute_reply":"2025-10-25T13:33:24.520743Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Huấn luyện hai mạng mô tả trong configs","metadata":{}},{"cell_type":"code","source":"os.makedirs('./snapshot', exist_ok=True)\n\nfor i, cfg in enumerate(configs):\n    print(cfg)\n    net = Net(cfg['l1'], cfg['l2'])\n    ######################\n    ### YOUR CODE HERE ###\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count()>1:\n            net = nn.DataParallel(net)\n    net.to(device)\n    criteration = CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=init_lr, momentum=0.9)\n    train(net, criterion=criteration, optimizer=optimizer, save_path=(f'./snapshot/model{i}.pth'), device=device)\n    ######################","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHabW0HfNQuj","outputId":"4a4c9bd0-7994-498b-c44e-fd7dadb46dd5","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:33:24.521809Z","iopub.execute_input":"2025-10-25T13:33:24.521975Z","iopub.status.idle":"2025-10-25T13:37:19.339239Z","shell.execute_reply.started":"2025-10-25T13:33:24.521961Z","shell.execute_reply":"2025-10-25T13:37:19.338255Z"}},"outputs":[{"name":"stdout","text":"{'l1': 64, 'l2': 32}\n[Epoch 1] loss: 2.302\n[Epoch 2] loss: 2.132\n[Epoch 3] loss: 1.776\n[Epoch 4] loss: 1.516\n[Epoch 5] loss: 1.394\n[Epoch 6] loss: 1.259\n[Epoch 7] loss: 1.201\n[Epoch 8] loss: 1.166\n[Epoch 9] loss: 1.145\n[Epoch 10] loss: 1.137\nFinished Training\nTest accuracy: 0.5747\n{'l1': 128, 'l2': 64}\n[Epoch 1] loss: 2.299\n[Epoch 2] loss: 2.079\n[Epoch 3] loss: 1.672\n[Epoch 4] loss: 1.482\n[Epoch 5] loss: 1.370\n[Epoch 6] loss: 1.206\n[Epoch 7] loss: 1.144\n[Epoch 8] loss: 1.101\n[Epoch 9] loss: 1.079\n[Epoch 10] loss: 1.070\nFinished Training\nTest accuracy: 0.6017\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Kết hợp kết quả hai mạng (ensemble)","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef test_ensemble(device=\"cuda:0\"):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in tqdm(testloader):\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            final_outputs = torch.zeros((4, 10)).to(device)\n            for i, cfg in enumerate(configs):\n                net = Net(cfg['l1'], cfg['l2'])\n                net.to(device) \n                net.load_state_dict(torch.load(f'./snapshot/model{i}.pth'))               \n                outputs = net(images)\n                final_outputs = final_outputs.add(outputs)\n\n            final_outputs.div(len(configs))\n            _, predicted = torch.max(final_outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total","metadata":{"id":"_W4q6zccShD5","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:37:19.340488Z","iopub.execute_input":"2025-10-25T13:37:19.341066Z","iopub.status.idle":"2025-10-25T13:37:19.347114Z","shell.execute_reply.started":"2025-10-25T13:37:19.341040Z","shell.execute_reply":"2025-10-25T13:37:19.346511Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"test_ensemble()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-zwy7Uxcmmh","outputId":"9c7ae6ee-e714-47e6-cba0-99ad31f993d3","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T13:37:19.348052Z","iopub.execute_input":"2025-10-25T13:37:19.348780Z","iopub.status.idle":"2025-10-25T13:37:44.237138Z","shell.execute_reply.started":"2025-10-25T13:37:19.348761Z","shell.execute_reply":"2025-10-25T13:37:44.236415Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2500/2500 [00:24<00:00, 100.52it/s]\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0.6066"},"metadata":{}}],"execution_count":17}]}